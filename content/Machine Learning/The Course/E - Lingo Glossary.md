
Use this to cross-reference whenever you forget a term. Or try learning it by heart and see how many times my definitions were way off when you start actually using these things. You do you ðŸ¤·

## A
**agent** - an AI that learns by acting on an environment and does its best to maximise the rewards it gets at each step.

## E
**environment** - the place where an agent acts and that responds to its actions. This can be a game or a real-life simulation.

## L
**loss functions** - is a formula that represents how much an AI loses with each mistake it makes. During training, the AI tries to minimise these losses.

## M
**model** - is the AI we train. It's called that because the mathematical formula that sits at core is a "model" (or a replica) of an ideal formula that solves a task. 

## R
**reinforcement learning** - when an AI learns which actions inside a environment give it the most reward. It's like the Groundhog Day, but you're training an AI.

**reward** - the amount of "points" an agent has gained from doing a action in a environment.

**reward functions** - a formula that defines how many "points" an agent should earn by taking a action in an environment. The AI will try to maximise it's total rewards when learning.

## S
**semi-supervised learning** - where there's a way to know how close you are to a target, but it's not exact. Like learning how to draw from imagination a lion after watching animal planet all day.

**supervised learning** - when the AI is given inputs and outputs and it needs to optimise a function that match those examples as close as possible. It's like you give the AI some ingredients and a bread and you tell it to figure out the recipe for baking bread is. 

## U
**unsupervised learning** - when the AI is given some data and it's told to find a certain number patterns inside it. As if you go out with some friends that speak multiple foreign languages and try to figure out how many languages they're speaking.